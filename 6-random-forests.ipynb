{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Random Forests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_classification(X_train, y_train, X_test, y_test, mode):\n",
    "    # Split the training data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the parameter grid to search over\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],  # Number of trees in the forest\n",
    "        'max_depth': [20, 30],  # Maximum depth of the tree\n",
    "    }\n",
    "\n",
    "    # Create a Random Forest classifier object\n",
    "    rf_model = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    if mode == \"BINARY\":\n",
    "        grid_search = GridSearchCV(\n",
    "            rf_model, param_grid, scoring='f1', cv=3, refit=True, verbose=3)\n",
    "    elif mode == \"MULTICLASS\":\n",
    "        grid_search = GridSearchCV(\n",
    "            rf_model, param_grid, scoring='f1_micro', cv=3, refit=True, verbose=3)\n",
    "\n",
    "    # Fit the GridSearchCV object to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters and score\n",
    "    print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "    # Use the model to make predictions on the test data\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Get the precision and recall scores\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # Get the F1 score\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')  # Use 'weighted' if you have imbalanced classes\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "def evaluation(y_test, y_pred, type, message):\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    if type == 'BINARY':\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    elif type == 'MULTICLASS':\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"{message}:\")\n",
    "    print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "    print(\"Precision: {:.4f}\".format(precision))\n",
    "    print(\"Recall: {:.4f}\".format(recall))\n",
    "    print(\"F1 Score: {:.4f}\".format(f1))\n",
    "    print(\"Confusion Matrix: \\n{}\\n\".format(conf_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwcX_train = pd.read_csv('./train-test-split/white-win-loss/wwcX_train.csv')\n",
    "wwcX_test = pd.read_csv('./train-test-split/white-win-loss/wwcX_test.csv')\n",
    "wwcY_train = pd.read_csv('./train-test-split/white-win-loss/wwcY_train.csv')\n",
    "wwcY_test = pd.read_csv('./train-test-split/white-win-loss/wwcY_test.csv')\n",
    "\n",
    "wtcX_train = pd.read_csv('./train-test-split/white-termination/wtcX_train.csv')\n",
    "wtcX_test = pd.read_csv('./train-test-split/white-termination/wtcX_test.csv')\n",
    "wtcY_train = pd.read_csv('./train-test-split/white-termination/wtcY_train.csv')\n",
    "wtcY_test = pd.read_csv('./train-test-split/white-termination/wtcY_test.csv')\n",
    "\n",
    "bwcX_train = pd.read_csv('./train-test-split/black-win-loss/bwcX_train.csv')\n",
    "bwcX_test = pd.read_csv('./train-test-split/black-win-loss/bwcX_test.csv')\n",
    "bwcY_train = pd.read_csv('./train-test-split/black-win-loss/bwcY_train.csv')\n",
    "bwcY_test = pd.read_csv('./train-test-split/black-win-loss/bwcY_test.csv')\n",
    "\n",
    "btcX_train = pd.read_csv('./train-test-split/black-termination/btcX_train.csv')\n",
    "btcX_test = pd.read_csv('./train-test-split/black-termination/btcX_test.csv')\n",
    "btcY_train = pd.read_csv('./train-test-split/black-termination/btcY_train.csv')\n",
    "btcY_test = pd.read_csv('./train-test-split/black-termination/btcY_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **White**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Win/Loss Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81     79792\n",
      "           1       0.81      0.82      0.81     82918\n",
      "\n",
      "    accuracy                           0.81    162710\n",
      "   macro avg       0.81      0.81      0.81    162710\n",
      "weighted avg       0.81      0.81      0.81    162710\n",
      "\n",
      "White Termination Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.07      0.07     53123\n",
      "           1       0.07      0.07      0.07     53396\n",
      "           2       0.73      0.60      0.66     56191\n",
      "\n",
      "    accuracy                           0.26    162710\n",
      "   macro avg       0.29      0.25      0.27    162710\n",
      "weighted avg       0.29      0.26      0.27    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### White Win/Loss Classification\n",
    "rf_wwc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_wwc.fit(wwcX_train, wwcY_train)\n",
    "wwcY_pred = rf_wwc.predict(wwcX_test)\n",
    "\n",
    "print(\"White Win/Loss Classification Report:\")\n",
    "print(classification_report(wwcY_test, wwcY_pred))\n",
    "\n",
    "### White Termination Classification\n",
    "rf_wtc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_wtc.fit(wtcX_train, wtcY_train)\n",
    "wtcY_pred = rf_wtc.predict(wtcX_test)\n",
    "\n",
    "print(\"White Termination Classification Report:\")\n",
    "print(classification_report(wtcY_test, wtcY_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Win/Loss Classification Report:\n",
      "Accuracy: 0.8107\n",
      "Precision: 0.8117\n",
      "Recall: 0.8183\n",
      "F1 Score: 0.8150\n",
      "Confusion Matrix: \n",
      "[[64049 15743]\n",
      " [15065 67853]]\n",
      "\n",
      "White Termination Classification Report:\n",
      "Accuracy: 0.2555\n",
      "Precision: 0.2949\n",
      "Recall: 0.2555\n",
      "F1 Score: 0.2730\n",
      "Confusion Matrix: \n",
      "[[ 3925 42872  6326]\n",
      " [43286  3790  6320]\n",
      " [11158 11180 33853]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### White Win/Loss Classification\n",
    "evaluation(wwcY_test, wwcY_pred, \"BINARY\", \"White Win/Loss Classification Report\")\n",
    "\n",
    "### White Termination Classification\n",
    "evaluation(wtcY_test, wtcY_pred, \"MULTICLASS\", \"White Termination Classification Report\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Black**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/Loss Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81     83059\n",
      "           1       0.81      0.80      0.80     79651\n",
      "\n",
      "    accuracy                           0.81    162710\n",
      "   macro avg       0.81      0.81      0.81    162710\n",
      "weighted avg       0.81      0.81      0.81    162710\n",
      "\n",
      "Termination Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.07      0.07     53123\n",
      "           1       0.07      0.07      0.07     53396\n",
      "           2       0.72      0.60      0.65     56191\n",
      "\n",
      "    accuracy                           0.25    162710\n",
      "   macro avg       0.29      0.25      0.27    162710\n",
      "weighted avg       0.29      0.25      0.27    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Black Win/Loss Classification\n",
    "rf_bwc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_bwc.fit(bwcX_train, bwcY_train)\n",
    "bwcY_pred = rf_bwc.predict(bwcX_test)\n",
    "\n",
    "print(\"Win/Loss Classification Report:\")\n",
    "print(classification_report(bwcY_test, bwcY_pred))\n",
    "\n",
    "### Black Termination Classification\n",
    "rf_btc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_btc.fit(btcX_train, btcY_train)\n",
    "btcY_pred = rf_btc.predict(btcX_test)\n",
    "\n",
    "print(\"Termination Classification Report:\")\n",
    "print(classification_report(btcY_test, btcY_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Win/Loss Classification Report:\n",
      "Accuracy: 0.8085\n",
      "Precision: 0.8079\n",
      "Recall: 0.7987\n",
      "F1 Score: 0.8033\n",
      "Confusion Matrix: \n",
      "[[67933 15126]\n",
      " [16030 63621]]\n",
      "\n",
      "Black Termination Classification Report:\n",
      "Accuracy: 0.2544\n",
      "Precision: 0.2940\n",
      "Recall: 0.2544\n",
      "F1 Score: 0.2721\n",
      "Confusion Matrix: \n",
      "[[ 3919 42789  6415]\n",
      " [43093  3906  6397]\n",
      " [11249 11366 33576]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Black Win/Loss Classification\n",
    "evaluation(bwcY_test, bwcY_pred, \"BINARY\", \"Black Win/Loss Classification Report\")\n",
    "\n",
    "### Black Termination Classification\n",
    "evaluation(btcY_test, btcY_pred, \"MULTICLASS\", \"Black Termination Classification Report\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Random Forests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **White**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) White Win/Loss Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Win-Loss Classification\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=100;, score=0.738 total time=  14.5s\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=100;, score=0.736 total time=  13.5s\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=100;, score=0.737 total time=  13.5s\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=200;, score=0.739 total time=  26.8s\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=200;, score=0.736 total time=  26.8s\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=200;, score=0.738 total time=  26.9s\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=100;, score=0.746 total time=  16.2s\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=100;, score=0.745 total time=  16.3s\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=100;, score=0.747 total time=  16.4s\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=200;, score=0.747 total time=  32.1s\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=200;, score=0.745 total time=  31.8s\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=200;, score=0.746 total time=  31.9s\n",
      "Best hyperparameters:  {'max_depth': 30, 'n_estimators': 200}\n",
      "Best score:  0.7461456396902532\n",
      "Precision: 0.7802255571121806\n",
      "Recall: 0.7802409194272018\n",
      "F1 Score: 0.7802176548396127\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77     79792\n",
      "           1       0.78      0.79      0.79     82918\n",
      "\n",
      "    accuracy                           0.78    162710\n",
      "   macro avg       0.78      0.78      0.78    162710\n",
      "weighted avg       0.78      0.78      0.78    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"White Win-Loss Classification\")\n",
    "rf_classification(wwcX_train, wwcY_train['W'], wwcX_test, wwcY_test['W'], \"BINARY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) White Termination Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Termination Classification\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=100;, score=0.354 total time=  13.9s\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=100;, score=0.351 total time=  13.9s\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=100;, score=0.355 total time=  13.9s\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=200;, score=0.352 total time=  27.6s\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=200;, score=0.350 total time=  27.5s\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=200;, score=0.352 total time=  27.7s\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=100;, score=0.321 total time=  19.6s\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=100;, score=0.320 total time=  19.5s\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=100;, score=0.320 total time=  19.6s\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=200;, score=0.322 total time=  38.7s\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=200;, score=0.321 total time=  38.9s\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=200;, score=0.321 total time=  38.7s\n",
      "Best hyperparameters:  {'max_depth': 20, 'n_estimators': 100}\n",
      "Best score:  0.3534962683523835\n",
      "Precision: 0.28634169752489963\n",
      "Recall: 0.31983283141786\n",
      "F1 Score: 0.29942448796807336\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.15      0.16     53123\n",
      "           1       0.16      0.14      0.15     53396\n",
      "           2       0.51      0.66      0.58     56191\n",
      "\n",
      "    accuracy                           0.32    162710\n",
      "   macro avg       0.28      0.31      0.29    162710\n",
      "weighted avg       0.29      0.32      0.30    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"White Termination Classification\")\n",
    "rf_classification(wtcX_train, wtcY_train['Termination'], wtcX_test, wtcY_test['Termination'], \"MULTICLASS\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Black**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Black Win/Loss Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Win-Loss Classification\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=100;, score=0.718 total time=  13.0s\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=100;, score=0.719 total time=  13.2s\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=100;, score=0.717 total time=  13.2s\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=200;, score=0.719 total time=  25.9s\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=200;, score=0.719 total time=  25.8s\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=200;, score=0.719 total time=  25.9s\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=100;, score=0.728 total time=  15.9s\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=100;, score=0.730 total time=  16.0s\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=100;, score=0.732 total time=  16.0s\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=200;, score=0.727 total time=  31.3s\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=200;, score=0.732 total time=  31.5s\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=200;, score=0.732 total time=  31.5s\n",
      "Best hyperparameters:  {'max_depth': 30, 'n_estimators': 200}\n",
      "Best score:  0.7301744496718733\n",
      "Precision: 0.7788397619027799\n",
      "Recall: 0.7788580910822936\n",
      "F1 Score: 0.7788407216435027\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78     83059\n",
      "           1       0.78      0.77      0.77     79651\n",
      "\n",
      "    accuracy                           0.78    162710\n",
      "   macro avg       0.78      0.78      0.78    162710\n",
      "weighted avg       0.78      0.78      0.78    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Black Win-Loss Classification\")\n",
    "rf_classification(bwcX_train, bwcY_train['B'], bwcX_test, bwcY_test['B'], \"BINARY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Black Termination Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Termination Classification\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=100;, score=0.353 total time=  14.1s\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=100;, score=0.352 total time=  13.8s\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=100;, score=0.354 total time=  13.9s\n",
      "[CV 1/3] END ....max_depth=20, n_estimators=200;, score=0.352 total time=  27.3s\n",
      "[CV 2/3] END ....max_depth=20, n_estimators=200;, score=0.352 total time=  27.8s\n",
      "[CV 3/3] END ....max_depth=20, n_estimators=200;, score=0.352 total time=  27.7s\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=100;, score=0.320 total time=  19.5s\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=100;, score=0.320 total time=  19.7s\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=100;, score=0.320 total time=  19.6s\n",
      "[CV 1/3] END ....max_depth=30, n_estimators=200;, score=0.320 total time=  38.9s\n",
      "[CV 2/3] END ....max_depth=30, n_estimators=200;, score=0.320 total time=  38.5s\n",
      "[CV 3/3] END ....max_depth=30, n_estimators=200;, score=0.320 total time=  39.0s\n",
      "Best hyperparameters:  {'max_depth': 20, 'n_estimators': 100}\n",
      "Best score:  0.352817654840999\n",
      "Precision: 0.2865831139822312\n",
      "Recall: 0.3187511523569541\n",
      "F1 Score: 0.29934940932657905\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.15      0.16     53123\n",
      "           1       0.16      0.14      0.15     53396\n",
      "           2       0.52      0.65      0.58     56191\n",
      "\n",
      "    accuracy                           0.32    162710\n",
      "   macro avg       0.28      0.31      0.29    162710\n",
      "weighted avg       0.29      0.32      0.30    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Black Termination Classification\")\n",
    "rf_classification(btcX_train, btcY_train['Termination'], btcX_test, btcY_test['Termination'], \"MULTICLASS\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually Win/Loss Classification performance got lower after hyperparameter tuning, but Termination Classification performance has improved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
