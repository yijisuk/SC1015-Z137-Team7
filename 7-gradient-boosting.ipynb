{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Gradient Boosting**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **White**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) White Win/Loss Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data\\\\train-test-split\\white-win-loss\\wwcX_train.csv\")\n",
    "X_test = pd.read_csv(\"data\\\\train-test-split\\white-win-loss\\wwcX_test.csv\")\n",
    "y_train = pd.read_csv(\"data\\\\train-test-split\\white-win-loss\\wwcY_train.csv\")\n",
    "y_test = pd.read_csv(\"data\\\\train-test-split\\white-win-loss\\wwcY_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best hyperparameters: OrderedDict([('algorithm', 'SAMME.R'), ('learning_rate', 0.0990326026579075), ('n_estimators', 1000)])\n",
      "Accuracy score: 0.6852895162869466\n",
      "Accuracy of AdaBoostClassifier: 0.68663880523631\n"
     ]
    }
   ],
   "source": [
    "# Convert y_train and y_test column vectors to 1-dimensional arrays\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "hyperparameters = {\n",
    "    'n_estimators': (50, 1000),\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "# Create AdaBoostClassifier object\n",
    "adaboost_clf = AdaBoostClassifier()\n",
    "\n",
    "# Define the search object with BayesSearchCV\n",
    "search = BayesSearchCV(\n",
    "    adaboost_clf,\n",
    "    hyperparameters,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the search object on the training data\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and accuracy score\n",
    "print('Best hyperparameters:', search.best_params_)\n",
    "print('Accuracy score:', search.best_score_)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = search.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of AdaBoostClassifier:', accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) White Win/Loss Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data\\\\train-test-split\\white-termination\\wtcX_train.csv\")\n",
    "X_test = pd.read_csv(\"data\\\\train-test-split\\white-termination\\wtcX_test.csv\")\n",
    "y_train = pd.read_csv(\"data\\\\train-test-split\\white-termination\\wtcY_train.csv\")\n",
    "y_test = pd.read_csv(\"data\\\\train-test-split\\white-termination\\wtcY_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "# Create AdaBoostClassifier object\n",
    "adaboost_clf = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1, random_state=30, algorithm='SAMME.R')\n",
    "\n",
    "# Fit the model on the training data\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = adaboost_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3751    0.3838    0.3794     53123\n",
      "           1     0.3832    0.2706    0.3172     53396\n",
      "           2     0.4934    0.6204    0.5497     56191\n",
      "\n",
      "    accuracy                         0.4283    162710\n",
      "   macro avg     0.4172    0.4249    0.4154    162710\n",
      "weighted avg     0.4186    0.4283    0.4178    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Black**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Black Win/Loss Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data\\\\train-test-split\\\\black-win-loss\\\\bwcX_train.csv\")\n",
    "X_test = pd.read_csv(\"data\\\\train-test-split\\\\black-win-loss\\\\bwcX_test.csv\")\n",
    "y_train = pd.read_csv(\"data\\\\train-test-split\\\\black-win-loss\\\\bwcY_train.csv\")\n",
    "y_test = pd.read_csv(\"data\\\\train-test-split\\\\black-win-loss\\\\bwcY_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoostClassifier: 0.6853666031589946\n"
     ]
    }
   ],
   "source": [
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "# Create AdaBoostClassifier object\n",
    "adaboost_clf = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1, random_state=30, algorithm='SAMME.R')\n",
    "\n",
    "# Fit the model on the training data\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = adaboost_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of AdaBoostClassifier:', accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Black Termination Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data\\\\train-test-split\\\\black-termination\\\\btcX_train.csv\")\n",
    "X_test = pd.read_csv(\"data\\\\train-test-split\\\\black-termination\\\\btcX_test.csv\")\n",
    "y_train = pd.read_csv(\"data\\\\train-test-split\\\\black-termination\\\\btcY_train.csv\")\n",
    "y_test = pd.read_csv(\"data\\\\train-test-split\\\\black-termination\\\\btcY_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3743    0.4000    0.3867     53123\n",
      "           1     0.3835    0.2530    0.3049     53396\n",
      "           2     0.4934    0.6209    0.5498     56191\n",
      "\n",
      "    accuracy                         0.4280    162710\n",
      "   macro avg     0.4171    0.4246    0.4138    162710\n",
      "weighted avg     0.4185    0.4280    0.4162    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "# Create AdaBoostClassifier object\n",
    "adaboost_clf = AdaBoostClassifier(n_estimators=1000, learning_rate=0.1, random_state=30, algorithm='SAMME.R')\n",
    "\n",
    "# Fit the model on the training data\n",
    "adaboost_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = adaboost_clf.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_classification(X_train, y_train, X_test, y_test, mode, save_file_name):\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # define the parameter grid to search over\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "        'max_depth': [3, 5, 7, 9, 11],\n",
    "        'n_estimators': [50, 100, 150, 200, 250],\n",
    "        'min_child_weight': [1, 3, 5, 7, 9]\n",
    "    }\n",
    "\n",
    "    # create an XGBoost classifier object\n",
    "    xgb_model = xgb.XGBClassifier(tree_method=\"gpu_hist\", gpu_id=0)\n",
    "\n",
    "    # create a GridSearchCV object\n",
    "    if mode == \"BINARY\":\n",
    "        grid_search = GridSearchCV(\n",
    "            xgb_model, param_grid, scoring='f1', cv=7, n_jobs=-1, refit=True)\n",
    "    elif mode == \"MULTICLASS\":\n",
    "        grid_search = GridSearchCV(\n",
    "            xgb_model, param_grid, scoring='f1_micro', cv=7, n_jobs=-1, refit=True)\n",
    "\n",
    "    # fit the GridSearchCV object to the data\n",
    "    grid_search.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "\n",
    "    # print the best hyperparameters and score\n",
    "    print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "    # Use the model to make predictions on the test data\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Get the precision and recall scores\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # Get the F1 score\n",
    "    # Use 'weighted' if you have imbalanced classes\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **White**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) White Win/Loss Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"/notebooks/train-test-split/white-win-loss/wwcX_train.csv\")\n",
    "X_test = pd.read_csv(\"/notebooks/train-test-split/white-win-loss/wwcX_test.csv\")\n",
    "y_train = pd.read_csv(\"/notebooks/train-test-split/white-win-loss/wwcY_train.csv\")\n",
    "y_test = pd.read_csv(\"/notebooks/train-test-split/white-win-loss/wwcY_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 375 candidates, totalling 1875 fits\n",
      "Best hyperparameters:  {'learning_rate': 1.0, 'max_depth': 11, 'min_child_weight': 1, 'n_estimators': 250}\n",
      "Best score:  0.7378939788141305\n",
      "Accuracy: 0.7496281728228136\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74     79792\n",
      "           1       0.75      0.76      0.75     82918\n",
      "\n",
      "    accuracy                           0.75    162710\n",
      "   macro avg       0.75      0.75      0.75    162710\n",
      "weighted avg       0.75      0.75      0.75    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'min_child_weight': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# create an XGBoost classifier object\n",
    "xgb_model = xgb.XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor')\n",
    "\n",
    "# create a GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, scoring='f1', cv=5, verbose=1, n_jobs=-1, refit=True)\n",
    "\n",
    "# fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7990535308217074\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79     79792\n",
      "           1       0.80      0.80      0.80     82918\n",
      "\n",
      "    accuracy                           0.80    162710\n",
      "   macro avg       0.80      0.80      0.80    162710\n",
      "weighted avg       0.80      0.80      0.80    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model_demo = xgb.XGBClassifier(\n",
    "    n_estimators=350, \n",
    "    max_depth=15, \n",
    "    learning_rate=1.0, \n",
    "    min_child_weight=1\n",
    "  )\n",
    "\n",
    "xgb_model_demo.fit(X_train, y_train)\n",
    "y_pred_demo = xgb_model_demo.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_demo)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report_demo = classification_report(y_test, y_pred_demo)\n",
    "print(\"Classification Report:\\n\", report_demo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) White Termination Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### White Termination Classification ###\n",
    "print(\"Starting White Termination Classification...\")\n",
    "\n",
    "wtcX_train = pd.read_csv('./train-test-split/white-termination/wtcX_train.csv')\n",
    "wtcX_test = pd.read_csv('./train-test-split/white-termination/wtcX_test.csv')\n",
    "wtcY_train = pd.read_csv('./train-test-split/white-termination/wtcY_train.csv')\n",
    "wtcY_test = pd.read_csv('./train-test-split/white-termination/wtcY_test.csv')\n",
    "\n",
    "xgboost_classification(\n",
    "    wtcX_train, wtcY_train['Termination'], wtcX_test, wtcY_test['Termination'], \"MULTICLASS\", \"wtc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./gb-results/white-termination.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Black**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Black Win/Loss Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 375 candidates, totalling 1875 fits\n",
      "Best hyperparameters:  {'learning_rate': 1.0, 'max_depth': 11, 'min_child_weight': 1, 'n_estimators': 250}\n",
      "Best score:  0.7208037263480291\n",
      "Accuracy: 0.7467088685391187\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75     83059\n",
      "           1       0.74      0.74      0.74     79651\n",
      "\n",
      "    accuracy                           0.75    162710\n",
      "   macro avg       0.75      0.75      0.75    162710\n",
      "weighted avg       0.75      0.75      0.75    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'min_child_weight': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# create an XGBoost classifier object\n",
    "xgb_model = xgb.XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor')\n",
    "\n",
    "# create a GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, scoring='f1', cv=5, verbose=1, n_jobs=-1, refit=True)\n",
    "\n",
    "# fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7957716182164587\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80     83059\n",
      "           1       0.79      0.79      0.79     79651\n",
      "\n",
      "    accuracy                           0.80    162710\n",
      "   macro avg       0.80      0.80      0.80    162710\n",
      "weighted avg       0.80      0.80      0.80    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model_demo = xgb.XGBClassifier(\n",
    "    n_estimators=350, \n",
    "    max_depth=15, \n",
    "    learning_rate=1.0, \n",
    "    min_child_weight=1\n",
    "  )\n",
    "\n",
    "xgb_model_demo.fit(X_train, y_train)\n",
    "y_pred_demo = xgb_model_demo.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_demo)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report_demo = classification_report(y_test, y_pred_demo)\n",
    "print(\"Classification Report:\\n\", report_demo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Black Termination Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Black Termination Classification ###\n",
    "print(\"Starting Black Termination Classification...\")\n",
    "\n",
    "btcX_train = pd.read_csv('./train-test-split/black-termination/btcX_train.csv')\n",
    "btcX_test = pd.read_csv('./train-test-split/black-termination/btcX_test.csv')\n",
    "btcY_train = pd.read_csv('./train-test-split/black-termination/btcY_train.csv')\n",
    "btcY_test = pd.read_csv('./train-test-split/black-termination/btcY_test.csv')\n",
    "\n",
    "xgboost_classification(\n",
    "    btcX_train, btcY_train['Termination'], btcX_test, btcY_test['Termination'], \"MULTICLASS\", \"btc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./gb-results/black-termination.png\">"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
