{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_classification(X_train, y_train, X_test, y_test, mode, save_file_name):\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # define the parameter grid to search over\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "        'max_depth': [3, 5, 7, 9, 11],\n",
    "        'n_estimators': [50, 100, 150, 200, 250],\n",
    "        'min_child_weight': [1, 3, 5, 7, 9]\n",
    "    }\n",
    "\n",
    "    # create an XGBoost classifier object\n",
    "    xgb_model = xgb.XGBClassifier(tree_method=\"gpu_hist\", gpu_id=0)\n",
    "\n",
    "    # create a GridSearchCV object\n",
    "    if mode == \"BINARY\":\n",
    "        grid_search = GridSearchCV(\n",
    "            xgb_model, param_grid, scoring='f1', cv=7, n_jobs=-1, refit=True)\n",
    "    elif mode == \"MULTICLASS\":\n",
    "        grid_search = GridSearchCV(\n",
    "            xgb_model, param_grid, scoring='f1_micro', cv=7, n_jobs=-1, refit=True)\n",
    "\n",
    "    # fit the GridSearchCV object to the data\n",
    "    grid_search.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "\n",
    "    # print the best hyperparameters and score\n",
    "    print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "    # Use the model to make predictions on the test data\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Get the precision and recall scores\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # Get the F1 score\n",
    "    # Use 'weighted' if you have imbalanced classes\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **White**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) White Win/Loss Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"/notebooks/train-test-split/white-win-loss/wwcX_train.csv\")\n",
    "X_test = pd.read_csv(\"/notebooks/train-test-split/white-win-loss/wwcX_test.csv\")\n",
    "y_train = pd.read_csv(\"/notebooks/train-test-split/white-win-loss/wwcY_train.csv\")\n",
    "y_test = pd.read_csv(\"/notebooks/train-test-split/white-win-loss/wwcY_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 375 candidates, totalling 1875 fits\n",
      "Best hyperparameters:  {'learning_rate': 1.0, 'max_depth': 11, 'min_child_weight': 1, 'n_estimators': 250}\n",
      "Best score:  0.7378939788141305\n",
      "Accuracy: 0.7496281728228136\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74     79792\n",
      "           1       0.75      0.76      0.75     82918\n",
      "\n",
      "    accuracy                           0.75    162710\n",
      "   macro avg       0.75      0.75      0.75    162710\n",
      "weighted avg       0.75      0.75      0.75    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'min_child_weight': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# create an XGBoost classifier object\n",
    "xgb_model = xgb.XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor')\n",
    "\n",
    "# create a GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, scoring='f1', cv=5, verbose=1, n_jobs=-1, refit=True)\n",
    "\n",
    "# fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7990535308217074\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79     79792\n",
      "           1       0.80      0.80      0.80     82918\n",
      "\n",
      "    accuracy                           0.80    162710\n",
      "   macro avg       0.80      0.80      0.80    162710\n",
      "weighted avg       0.80      0.80      0.80    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model_demo = xgb.XGBClassifier(\n",
    "    n_estimators=350, \n",
    "    max_depth=15, \n",
    "    learning_rate=1.0, \n",
    "    min_child_weight=1\n",
    "  )\n",
    "\n",
    "xgb_model_demo.fit(X_train, y_train)\n",
    "y_pred_demo = xgb_model_demo.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_demo)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report_demo = classification_report(y_test, y_pred_demo)\n",
    "print(\"Classification Report:\\n\", report_demo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) White Termination Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### White Termination Classification ###\n",
    "print(\"Starting White Termination Classification...\")\n",
    "\n",
    "wtcX_train = pd.read_csv('./train-test-split/white-termination/wtcX_train.csv')\n",
    "wtcX_test = pd.read_csv('./train-test-split/white-termination/wtcX_test.csv')\n",
    "wtcY_train = pd.read_csv('./train-test-split/white-termination/wtcY_train.csv')\n",
    "wtcY_test = pd.read_csv('./train-test-split/white-termination/wtcY_test.csv')\n",
    "\n",
    "xgboost_classification(\n",
    "    wtcX_train, wtcY_train['Termination'], wtcX_test, wtcY_test['Termination'], \"MULTICLASS\", \"wtc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./gb-results/white-termination.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Black**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Black Win/Loss Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 375 candidates, totalling 1875 fits\n",
      "Best hyperparameters:  {'learning_rate': 1.0, 'max_depth': 11, 'min_child_weight': 1, 'n_estimators': 250}\n",
      "Best score:  0.7208037263480291\n",
      "Accuracy: 0.7467088685391187\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75     83059\n",
      "           1       0.74      0.74      0.74     79651\n",
      "\n",
      "    accuracy                           0.75    162710\n",
      "   macro avg       0.75      0.75      0.75    162710\n",
      "weighted avg       0.75      0.75      0.75    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    'n_estimators': [50, 100, 150, 200, 250],\n",
    "    'min_child_weight': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "# create an XGBoost classifier object\n",
    "xgb_model = xgb.XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor')\n",
    "\n",
    "# create a GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, scoring='f1', cv=5, verbose=1, n_jobs=-1, refit=True)\n",
    "\n",
    "# fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters and score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7957716182164587\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80     83059\n",
      "           1       0.79      0.79      0.79     79651\n",
      "\n",
      "    accuracy                           0.80    162710\n",
      "   macro avg       0.80      0.80      0.80    162710\n",
      "weighted avg       0.80      0.80      0.80    162710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model_demo = xgb.XGBClassifier(\n",
    "    n_estimators=350, \n",
    "    max_depth=15, \n",
    "    learning_rate=1.0, \n",
    "    min_child_weight=1\n",
    "  )\n",
    "\n",
    "xgb_model_demo.fit(X_train, y_train)\n",
    "y_pred_demo = xgb_model_demo.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_demo)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "report_demo = classification_report(y_test, y_pred_demo)\n",
    "print(\"Classification Report:\\n\", report_demo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Black Termination Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Black Termination Classification ###\n",
    "print(\"Starting Black Termination Classification...\")\n",
    "\n",
    "btcX_train = pd.read_csv('./train-test-split/black-termination/btcX_train.csv')\n",
    "btcX_test = pd.read_csv('./train-test-split/black-termination/btcX_test.csv')\n",
    "btcY_train = pd.read_csv('./train-test-split/black-termination/btcY_train.csv')\n",
    "btcY_test = pd.read_csv('./train-test-split/black-termination/btcY_test.csv')\n",
    "\n",
    "xgboost_classification(\n",
    "    btcX_train, btcY_train['Termination'], btcX_test, btcY_test['Termination'], \"MULTICLASS\", \"btc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./gb-results/black-termination.png\">"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
